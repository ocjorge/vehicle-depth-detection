# Vehicle Detection with Depth Estimation

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.x-green.svg)](https://opencv.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-Latest-red.svg)](https://pytorch.org/)
[![YOLO](https://img.shields.io/badge/YOLO-Ultralytics-yellow.svg)](https://ultralytics.com/)
[![MiDaS](https://img.shields.io/badge/MiDaS-Intel-orange.svg)](https://github.com/isl-org/MiDaS)
[![License](https://img.shields.io/badge/License-MIT-lightgrey.svg)](LICENSE)

## ğŸ“‹ DescripciÃ³n

Este proyecto combina **detecciÃ³n de objetos vehiculares** con **estimaciÃ³n de profundidad** para analizar videos de trÃ¡fico. Utiliza un modelo YOLO personalizado para detectar vehÃ­culos y el modelo MiDaS de Intel para calcular mapas de profundidad, proporcionando informaciÃ³n espacial completa de la escena.

## âœ¨ CaracterÃ­sticas

- ğŸš— **DetecciÃ³n multi-clase**: Identifica carros, buses, camiones, motocicletas, bicicletas, personas y mÃ¡s
- ğŸ“ **EstimaciÃ³n de profundidad**: Calcula distancias relativas usando MiDaS DPT_Large
- ğŸ¥ **Procesamiento de video**: Analiza videos completos con control de rendimiento
- ğŸ›¡ï¸ **Robusto y seguro**: Incluye manejo de errores y lÃ­mites de tiempo de ejecuciÃ³n
- âš¡ **Optimizado**: Soporte para GPU y opciones de salto de frames

## ğŸ”§ Requisitos

### Dependencias principales
```
torch>=1.9.0
torchvision>=0.10.0
opencv-python>=4.5.0
ultralytics>=8.0.0
Pillow>=8.0.0
numpy>=1.21.0
```

### Hardware recomendado
- **GPU**: NVIDIA con soporte CUDA (recomendado)
- **RAM**: MÃ­nimo 8GB, recomendado 16GB+
- **Almacenamiento**: Espacio suficiente para videos de entrada y salida

## ğŸš€ InstalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone https://github.com/tu-usuario/vehicle-depth-detection.git
cd vehicle-depth-detection
```

2. **Crear entorno virtual**
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Descargar modelo personalizado**
   - Coloca tu modelo YOLO entrenado (`best.pt`) en la carpeta del proyecto
   - Los modelos MiDaS se descargan automÃ¡ticamente en la primera ejecuciÃ³n

## ğŸ“– Uso

### ConfiguraciÃ³n bÃ¡sica

1. **Editar rutas en el cÃ³digo**:
```python
VIDEO_INPUT_PATH = 'ruta/a/tu/video.mp4'
OUTPUT_VIDEO_PATH = 'video_procesado.mp4'
model_vehicles = YOLO('ruta/a/tu/modelo.pt')
```

2. **Ejecutar el procesamiento**:
```bash
python main.py
```

### ParÃ¡metros configurables

| ParÃ¡metro | DescripciÃ³n | Valor por defecto |
|-----------|-------------|-------------------|
| `CONFIDENCE_THRESHOLD` | Umbral de confianza para detecciones | 0.35 |
| `FRAME_SKIP` | Frames a saltar (0 = procesar todos) | 0 |
| `MAX_EXECUTION_TIME` | Tiempo mÃ¡ximo de ejecuciÃ³n (segundos) | 7200 (2 horas) |

## ğŸ¯ Clases detectadas

El modelo puede identificar las siguientes clases de objetos:

- ğŸš— **car** - AutomÃ³viles (tamaÃ±o real: 1.8m)
- ğŸ›º **threewheel** - VehÃ­culos de tres ruedas (1.2m)
- ğŸšŒ **bus** - Autobuses (2.5m)
- ğŸšš **truck** - Camiones (2.6m)
- ğŸï¸ **motorbike** - Motocicletas (0.8m)
- ğŸš **van** - Camionetas (2.0m)
- ğŸ‘¤ **person** - Personas (0.5m)
- ğŸš² **bicycle** - Bicicletas (0.4m)
- ğŸ• **dog** - Perros (0.3m)

## ğŸ”„ Flujo de procesamiento

1. **Carga de modelos**: YOLO personalizado + MiDaS DPT_Large
2. **Lectura de video**: Frame por frame con manejo de errores
3. **EstimaciÃ³n de profundidad**: ConversiÃ³n RGB â†’ Tensor â†’ Mapa de profundidad
4. **DetecciÃ³n de objetos**: IdentificaciÃ³n y localizaciÃ³n de vehÃ­culos
5. **VisualizaciÃ³n**: Dibujo de bounding boxes
6. **Guardado**: ExportaciÃ³n del video procesado

## ğŸ“Š Rendimiento

- **Velocidad**: Depende del hardware (GPU recomendada)
- **PrecisiÃ³n**: Ajustable mediante `CONFIDENCE_THRESHOLD`
- **Memoria**: Optimizado para videos de alta resoluciÃ³n
- **Tiempo**: Progreso reportado cada 100 frames

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -m 'AÃ±adir nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- [Ultralytics](https://ultralytics.com/) por YOLO
- [Intel ISL](https://github.com/isl-org/MiDaS) por MiDaS
- [OpenCV](https://opencv.org/) por las herramientas de visiÃ³n computacional
- [PyTorch](https://pytorch.org/) por el framework de deep learning

## ğŸ“ Contacto

- **Autor**: Tu Nombre
- **Email**: tu.email@ejemplo.com
- **GitHub**: [@tu-usuario](https://github.com/tu-usuario)

---

â­ **Â¡No olvides dar una estrella al proyecto si te resulta Ãºtil!**
